{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple interface for helmet on head detection using trained model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предварительная установка пакетов (для Colab)\n",
    "#!pip install torchinfo ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#import cv2\n",
    "import os\n",
    "import json\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "#import typing\n",
    "#import xml.etree.ElementTree as ET\n",
    "#import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops import box_convert\n",
    "from torchinfo import summary\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.mobilenetv3 import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image, pil_to_tensor\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms._presets import ObjectDetection\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import smooth_l1_loss, cross_entropy\n",
    "#?\n",
    "from torchvision.models.detection.ssdlite import SSDLiteClassificationHead\n",
    "#from ultralytics import YOLO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose place and set default path to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем путь до датасета\n",
    "\n",
    "# Локально\n",
    "#ds_path = '/home/vovk/SberUniversity/DS_from_03_10_2022/PM_Group_AN/FinalProj/HelmetDetection/VOC2028/'\n",
    "# relative path\n",
    "ds_path = 'VOC2028/'\n",
    "\n",
    "# Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# ds_path = '/content/drive/MyDrive/SberUniversity/PM_DS14AN/Fin/HelmetDetection/VOC2028/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepairing **SSDLite** model for prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create template for loading model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = ssdlite320_mobilenet_v3_large( weights='DEFAULT',\n",
    "                                      weights_backbone=MobileNet_V3_Large_Weights.IMAGENET1K_V1,\n",
    "                                      score_tresh=0.25\n",
    "                                     )\n",
    "\n",
    "m_3class = ssdlite320_mobilenet_v3_large( num_classes=3,\n",
    "                                          weights_backbone=None,\n",
    "                                          score_tresh=0.25,\n",
    "                                        )\n",
    "\n",
    "model_loaded.head = m_3class.head"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained 19 epoches\n",
      "Boxes loss: 1.6028, class loss: 1.9784\n"
     ]
    }
   ],
   "source": [
    "best_path = ds_path + 'tmp/models/' + 'SSDLiteMobNetFreezBackbone_3class_best.pt'\n",
    "checkpoint = torch.load(best_path)\n",
    "model_loaded.load_state_dict(checkpoint['model_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "print('Model trained', epoch, 'epoches')\n",
    "print(f'Boxes loss: {round(loss[\"bbox_loss\"].item(),4)}, class loss: {round(loss[\"cls_loss\"].item(),4)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using trained **SSDLite** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Colab\n",
    "#from google.colab import files\n",
    "#img1 = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[359.5716,  57.1137, 447.9247, 186.7525],\n",
      "        [247.6188,  44.8378, 349.3846, 172.3196],\n",
      "        [ 19.2173, 212.3813, 113.1847, 309.3752]], grad_fn=<StackBackward0>), 'scores': tensor([0.9081, 0.8517, 0.5148], grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2])}\n"
     ]
    }
   ],
   "source": [
    "img1 = Image.open(ds_path + 'short_test/'+ \"hard_hat_workers15.png\")\n",
    "convert_to_tensor = ObjectDetection() # Универсальное преобразование (используется в исходниках ssdlite)\n",
    "tensor_img1 = convert_to_tensor(img1)\n",
    "model_loaded.eval()\n",
    "model_loaded.score_thresh = 0.4\n",
    "prediction = model_loaded([tensor_img1])[0]\n",
    "\n",
    "labels_dict={'1': 'head',\n",
    "             '2': 'helmet'}\n",
    "\n",
    "labels = [labels_dict[str(label.item())] + ': ' + \\\n",
    "          str(round(prediction[\"scores\"][idx].item(), 2)) \\\n",
    "          for idx, label in enumerate(prediction[\"labels\"])]\n",
    "\n",
    "box = draw_bounding_boxes(pil_to_tensor(img1), # for original image case\n",
    "                          #(tensor_img1*256).to(dtype=torch.uint8), # for normalized image case (not fully identical)\n",
    "                          boxes=prediction['boxes'],\n",
    "                          labels=labels,\n",
    "                          colors='red',\n",
    "                          width=3)\n",
    "im = to_pil_image(box.detach())\n",
    "im.show()\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
